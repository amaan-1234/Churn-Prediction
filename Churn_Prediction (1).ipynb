{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07XfCWqdN-SR",
    "outputId": "aa77474d-fadf-498f-825f-9e860e9ff8f2"
   },
   "outputs": [],
   "source": [
    "# Download the real dataset\n",
    "!wget https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv -O WA_Fn-UseC_-Telco-Customer-Churn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRdkTC4W-1xY",
    "outputId": "09a70195-28a8-4b04-ecaf-56b892ef386e"
   },
   "outputs": [],
   "source": [
    "# Step 1: Environment Setup and Data Loading\n",
    "\n",
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost shap lime streamlit kaggle plotly kagglehub[pandas-datasets]\n",
    "\n",
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✅ Environment setup complete!\")\n",
    "print(\"📊 Ready to load the Telco Customer Churn dataset\")\n",
    "\n",
    "# Load dataset using kagglehub\n",
    "try:\n",
    "    import kagglehub\n",
    "    from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "    file_path = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"  # Required file within the dataset\n",
    "\n",
    "    # Load the latest version of the dataset\n",
    "    df = kagglehub.load_dataset(\n",
    "        KaggleDatasetAdapter.PANDAS,\n",
    "        \"blastchar/telco-customer-churn\",\n",
    "        file_path\n",
    "    )\n",
    "\n",
    "    print(\"✅ Dataset loaded successfully using KaggleHub!\")\n",
    "    print(f\"📈 Shape: {df.shape}\")\n",
    "    print(f\"🔍 Columns: {list(df.columns)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"⚠️ KaggleHub failed or is not configured correctly.\")\n",
    "    print(f\"Reason: {e}\")\n",
    "    print(\"🔁 Trying to load the dataset manually (make sure it's uploaded)...\")\n",
    "    try:\n",
    "        df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "        print(\"✅ Dataset loaded manually!\")\n",
    "        print(f\"📈 Shape: {df.shape}\")\n",
    "        print(f\"🔍 Columns: {list(df.columns)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Dataset not found. Please upload the Telco Customer Churn CSV file.\")\n",
    "        print(\"You can download it from: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\")\n",
    "\n",
    "# Display a sample of the dataset\n",
    "try:\n",
    "    print(\"\\n📋 First 5 records:\\n\", df.head())\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zog67RUw-2SE",
    "outputId": "13b7ddee-dd5c-48f9-829b-91cd5063997e"
   },
   "outputs": [],
   "source": [
    "# Step 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"COLUMN INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\" * 50)\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_table = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "print(missing_table[missing_table['Missing Count'] > 0])\n",
    "\n",
    "# Check unique values in categorical columns\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CATEGORICAL COLUMNS UNIQUE VALUES\")\n",
    "print(\"=\" * 50)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "    print(f\"  → Unique count: {df[col].nunique()}\")\n",
    "    print()\n",
    "\n",
    "# Analyze target variable distribution\n",
    "print(\"=\" * 50)\n",
    "print(\"TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "churn_percentage = df['Churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Churn Distribution:\")\n",
    "for category, count in churn_counts.items():\n",
    "    percentage = churn_percentage[category]\n",
    "    print(f\"  {category}: {count} ({percentage:.2f}%)\")\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Churn distribution\n",
    "axes[0, 0].pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Customer Churn Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Tenure distribution\n",
    "axes[0, 1].hist(df['tenure'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 1].set_title('Customer Tenure Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Tenure (months)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# 3. Monthly charges distribution\n",
    "axes[1, 0].hist(df['MonthlyCharges'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1, 0].set_title('Monthly Charges Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Monthly Charges ($)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 4. Total charges vs Churn\n",
    "# First, clean the TotalCharges column (it might have some issues)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'].fillna(0, inplace=True)\n",
    "\n",
    "churn_yes = df[df['Churn'] == 'Yes']['TotalCharges']\n",
    "churn_no = df[df['Churn'] == 'No']['TotalCharges']\n",
    "\n",
    "axes[1, 1].hist([churn_no, churn_yes], bins=30, alpha=0.7,\n",
    "                label=['No Churn', 'Churn'], color=['green', 'red'])\n",
    "axes[1, 1].set_title('Total Charges by Churn Status', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Total Charges ($)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ EDA completed! Key insights discovered for feature engineering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Mp51zPo_Bk-",
    "outputId": "053f0047-5eee-47be-f835-f94f602c5ab7"
   },
   "outputs": [],
   "source": [
    "# Step 3: Data Preprocessing and Feature Engineering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a copy of the dataframe for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "print(\"🔧 STARTING DATA PREPROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Handle TotalCharges column (convert to numeric and handle missing values)\n",
    "print(\"1. Cleaning TotalCharges column...\")\n",
    "df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
    "total_charges_missing = df_processed['TotalCharges'].isnull().sum()\n",
    "print(f\"   → Missing values in TotalCharges: {total_charges_missing}\")\n",
    "\n",
    "# Fill missing TotalCharges with 0 (likely new customers)\n",
    "df_processed['TotalCharges'].fillna(0, inplace=True)\n",
    "\n",
    "# 2. Create new features (Feature Engineering)\n",
    "print(\"\\n2. Creating new features...\")\n",
    "\n",
    "# Tenure categories\n",
    "def categorize_tenure(tenure):\n",
    "    if tenure <= 12:\n",
    "        return 'New'\n",
    "    elif tenure <= 24:\n",
    "        return 'Medium'\n",
    "    elif tenure <= 48:\n",
    "        return 'Long'\n",
    "    else:\n",
    "        return 'Veteran'\n",
    "\n",
    "df_processed['TenureCategory'] = df_processed['tenure'].apply(categorize_tenure)\n",
    "\n",
    "# Average monthly charges per tenure month\n",
    "df_processed['AvgChargesPerMonth'] = df_processed['TotalCharges'] / (df_processed['tenure'] + 1)\n",
    "\n",
    "# Contract value categorization\n",
    "def categorize_contract(contract):\n",
    "    if contract == 'Month-to-month':\n",
    "        return 'Flexible'\n",
    "    elif contract == 'One year':\n",
    "        return 'Medium_term'\n",
    "    else:\n",
    "        return 'Long_term'\n",
    "\n",
    "df_processed['ContractCategory'] = df_processed['Contract'].apply(categorize_contract)\n",
    "\n",
    "# Service count (number of additional services)\n",
    "service_columns = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                  'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "df_processed['ServiceCount'] = (df_processed[service_columns] == 'Yes').sum(axis=1)\n",
    "\n",
    "# Total service value indicator\n",
    "df_processed['HasMultipleServices'] = (df_processed['ServiceCount'] > 2).astype(int)\n",
    "\n",
    "print(f\"   → Created TenureCategory: {df_processed['TenureCategory'].unique()}\")\n",
    "print(f\"   → Created AvgChargesPerMonth (sample): {df_processed['AvgChargesPerMonth'].head(3).values}\")\n",
    "print(f\"   → Created ContractCategory: {df_processed['ContractCategory'].unique()}\")\n",
    "print(f\"   → Created ServiceCount (range): {df_processed['ServiceCount'].min()} - {df_processed['ServiceCount'].max()}\")\n",
    "\n",
    "# 3. Handle categorical variables\n",
    "print(\"\\n3. Encoding categorical variables...\")\n",
    "\n",
    "# Binary categorical variables (Yes/No) - convert to 1/0\n",
    "binary_columns = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
    "for col in binary_columns:\n",
    "    df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0})\n",
    "    print(f\"   → Encoded {col}: {df_processed[col].unique()}\")\n",
    "\n",
    "# Handle 'No internet service' and 'No phone service' in other columns\n",
    "internet_columns = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "for col in internet_columns:\n",
    "    df_processed[col] = df_processed[col].replace({'No internet service': 'No'})\n",
    "    df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Handle MultipleLines\n",
    "df_processed['MultipleLines'] = df_processed['MultipleLines'].replace({'No phone service': 'No'})\n",
    "df_processed['MultipleLines'] = df_processed['MultipleLines'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# One-hot encode remaining categorical variables\n",
    "categorical_to_encode = ['gender', 'InternetService', 'Contract', 'PaymentMethod', 'TenureCategory', 'ContractCategory']\n",
    "\n",
    "print(f\"   → One-hot encoding: {categorical_to_encode}\")\n",
    "df_processed = pd.get_dummies(df_processed, columns=categorical_to_encode, prefix=categorical_to_encode)\n",
    "\n",
    "print(f\"   → Dataset shape after encoding: {df_processed.shape}\")\n",
    "\n",
    "# 4. Feature scaling for numerical variables\n",
    "print(\"\\n4. Scaling numerical features...\")\n",
    "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'AvgChargesPerMonth', 'ServiceCount']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_processed[numerical_features] = scaler.fit_transform(df_processed[numerical_features])\n",
    "\n",
    "print(f\"   → Scaled features: {numerical_features}\")\n",
    "\n",
    "# 5. Prepare final dataset\n",
    "print(\"\\n5. Preparing final dataset...\")\n",
    "\n",
    "# Remove customerID as it's not needed for modeling\n",
    "if 'customerID' in df_processed.columns:\n",
    "    df_processed = df_processed.drop('customerID', axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_processed.drop('Churn', axis=1)\n",
    "y = df_processed['Churn']\n",
    "\n",
    "print(f\"   → Final feature matrix shape: {X.shape}\")\n",
    "print(f\"   → Target variable shape: {y.shape}\")\n",
    "print(f\"   → Feature columns: {list(X.columns)}\")\n",
    "\n",
    "# 6. Train-test split\n",
    "print(\"\\n6. Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"   → Training set: {X_train.shape}\")\n",
    "print(f\"   → Test set: {X_test.shape}\")\n",
    "print(f\"   → Training target distribution:\")\n",
    "print(f\"     - No Churn: {(y_train == 0).sum()} ({(y_train == 0).mean():.2%})\")\n",
    "print(f\"     - Churn: {(y_train == 1).sum()} ({(y_train == 1).mean():.2%})\")\n",
    "\n",
    "print(\"\\n✅ DATA PREPROCESSING COMPLETED!\")\n",
    "print(\"📊 Ready for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4Jc0V_X2_Dek",
    "outputId": "749db083-f3f1-43b7-f8b4-66cc9d32549b"
   },
   "outputs": [],
   "source": [
    "# Step 4: Model Training and Evaluation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import time\n",
    "\n",
    "print(\"🤖 STARTING MODEL TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "model_results = {}\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Comprehensive model evaluation function\"\"\"\n",
    "\n",
    "    print(f\"\\n📈 Training {model_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Training Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'Test Accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'Precision': precision_score(y_test, y_test_pred),\n",
    "        'Recall': recall_score(y_test, y_test_pred),\n",
    "        'F1 Score': f1_score(y_test, y_test_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_test_pred_proba),\n",
    "        'Training Time (s)': training_time\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    metrics['CV ROC AUC Mean'] = cv_scores.mean()\n",
    "    metrics['CV ROC AUC Std'] = cv_scores.std()\n",
    "\n",
    "    print(f\"   ⏱️  Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"   🎯 Test Accuracy: {metrics['Test Accuracy']:.4f}\")\n",
    "    print(f\"   🎯 ROC AUC: {metrics['ROC AUC']:.4f}\")\n",
    "    print(f\"   🎯 F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "\n",
    "    return model, metrics, y_test_pred, y_test_pred_proba\n",
    "\n",
    "# Train and evaluate all models\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    trained_model, metrics, predictions, probabilities = evaluate_model(\n",
    "        model, X_train, X_test, y_train, y_test, model_name\n",
    "    )\n",
    "\n",
    "    trained_models[model_name] = {\n",
    "        'model': trained_model,\n",
    "        'metrics': metrics,\n",
    "        'predictions': predictions,\n",
    "        'probabilities': probabilities\n",
    "    }\n",
    "\n",
    "    model_results[model_name] = metrics\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(model_results).T\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "# Sort by ROC AUC score\n",
    "comparison_df = comparison_df.sort_values('ROC AUC', ascending=False)\n",
    "print(comparison_df)\n",
    "\n",
    "# Identify best model\n",
    "best_model_name = comparison_df.index[0]\n",
    "best_model = trained_models[best_model_name]['model']\n",
    "best_predictions = trained_models[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\n🏆 BEST MODEL: {best_model_name}\")\n",
    "print(f\"   🎯 ROC AUC Score: {comparison_df.loc[best_model_name, 'ROC AUC']:.4f}\")\n",
    "\n",
    "# Detailed evaluation of best model\n",
    "print(f\"\\n📊 DETAILED EVALUATION - {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_predictions, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Model Comparison - ROC AUC\n",
    "axes[0, 0].bar(comparison_df.index, comparison_df['ROC AUC'], color=['gold', 'silver', 'chocolate'])\n",
    "axes[0, 0].set_title('Model Comparison - ROC AUC Score', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('ROC AUC Score')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(comparison_df['ROC AUC']):\n",
    "    axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1])\n",
    "axes[0, 1].set_title(f'Confusion Matrix - {best_model_name}', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Predicted')\n",
    "axes[0, 1].set_ylabel('Actual')\n",
    "\n",
    "# 3. Feature Importance (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "    axes[1, 0].barh(feature_importance['feature'], feature_importance['importance'])\n",
    "    axes[1, 0].set_title(f'Top 10 Feature Importance - {best_model_name}', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Importance')\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': abs(best_model.coef_[0])\n",
    "    }).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "    axes[1, 0].barh(feature_importance['feature'], feature_importance['importance'])\n",
    "    axes[1, 0].set_title(f'Top 10 Feature Importance - {best_model_name}', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Absolute Coefficient Value')\n",
    "\n",
    "# 4. Precision-Recall by Model\n",
    "precision_scores = [model_results[name]['Precision'] for name in model_results.keys()]\n",
    "recall_scores = [model_results[name]['Recall'] for name in model_results.keys()]\n",
    "\n",
    "axes[1, 1].scatter(recall_scores, precision_scores, s=100, alpha=0.7)\n",
    "for i, name in enumerate(model_results.keys()):\n",
    "    axes[1, 1].annotate(name, (recall_scores[i], precision_scores[i]),\n",
    "                       xytext=(5, 5), textcoords='offset points')\n",
    "axes[1, 1].set_xlabel('Recall')\n",
    "axes[1, 1].set_ylabel('Precision')\n",
    "axes[1, 1].set_title('Precision vs Recall by Model', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ MODEL TRAINING COMPLETED!\")\n",
    "print(f\"🎯 Best performing model: {best_model_name}\")\n",
    "print(f\"📊 Ready for model explainability analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0d8c3f3bdb71408c8817c8439bc3bb87",
      "3ce53c5ec93842008f334b05aa74ec6a",
      "033873cc805f4201ab8ce5e4e207d20f",
      "a1a9c9b16d5b495fade74bc6a2351f82",
      "fa63cd19329d4de29c04f512c08e81b6",
      "4a0e909118b9492b9ac9932fb6df9ebd",
      "fd0beba708c34108ae2f131b88ff0a84",
      "66e114019955420a84ada1a133141689",
      "c302a6a104034550b9c296f35ab6103e",
      "d3c479d95e32484298c1f76b4baf7fbb",
      "80dd2d351c1c487b9059ca377fe770f7"
     ]
    },
    "id": "Cz_-rvBA_Fdv",
    "outputId": "1efe04eb-0c31-46ea-8257-316aecd49345"
   },
   "outputs": [],
   "source": [
    "# Step 5: Model Explainability with SHAP and LIME (Fixed Version)\n",
    "\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🔍 STARTING MODEL EXPLAINABILITY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fix for SHAP compatibility issues\n",
    "def safe_shap_analysis(model, X_train, X_test, model_name):\n",
    "    \"\"\"Safely initialize SHAP explainer with error handling\"\"\"\n",
    "    try:\n",
    "        if model_name == 'XGBoost':\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "            expected_value = explainer.expected_value\n",
    "        elif model_name == 'Random Forest':\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "            # For RandomForest, SHAP returns values for both classes, we want the positive class\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_values = shap_values[1]\n",
    "                expected_value = explainer.expected_value[1]\n",
    "            else:\n",
    "                expected_value = explainer.expected_value\n",
    "        else:  # Logistic Regression\n",
    "            # Use KernelExplainer for more stability with Logistic Regression\n",
    "            explainer = shap.KernelExplainer(model.predict_proba, shap.sample(X_train, 100))\n",
    "            shap_values = explainer.shap_values(X_test.iloc[:100])  # Limit samples for performance\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_values = shap_values[1]  # Take positive class\n",
    "            expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "\n",
    "        return explainer, shap_values, expected_value, True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error with SHAP TreeExplainer: {e}\")\n",
    "        print(\"🔄 Falling back to KernelExplainer...\")\n",
    "        try:\n",
    "            # Fallback to KernelExplainer which is more stable\n",
    "            background_sample = shap.sample(X_train, min(100, len(X_train)))\n",
    "            explainer = shap.KernelExplainer(model.predict_proba, background_sample)\n",
    "            test_sample = X_test.iloc[:min(50, len(X_test))]  # Limit for performance\n",
    "            shap_values = explainer.shap_values(test_sample)\n",
    "\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_values = shap_values[1]  # Take positive class\n",
    "            expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "\n",
    "            return explainer, shap_values, expected_value, True\n",
    "\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Error with KernelExplainer: {e2}\")\n",
    "            return None, None, None, False\n",
    "\n",
    "# Initialize SHAP explainer for the best model\n",
    "print(f\"1. Setting up SHAP explainer for {best_model_name}...\")\n",
    "\n",
    "explainer, shap_values, expected_value, shap_success = safe_shap_analysis(best_model, X_train, X_test, best_model_name)\n",
    "\n",
    "if shap_success:\n",
    "    print(\"   ✅ SHAP explainer initialized successfully!\")\n",
    "\n",
    "    # Debug: Check SHAP values shape and type\n",
    "    print(f\"   🔍 SHAP values shape: {shap_values.shape}\")\n",
    "    print(f\"   🔍 SHAP values type: {type(shap_values)}\")\n",
    "\n",
    "    # Ensure we have the right data dimensions\n",
    "    if isinstance(shap_values, list):\n",
    "        # If it's a list, take the positive class (index 1)\n",
    "        shap_values = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "\n",
    "    # Convert to numpy array if needed\n",
    "    if not isinstance(shap_values, np.ndarray):\n",
    "        shap_values = np.array(shap_values)\n",
    "\n",
    "    # Ensure 2D array (samples, features)\n",
    "    if shap_values.ndim == 1:\n",
    "        shap_values = shap_values.reshape(1, -1)\n",
    "    elif shap_values.ndim > 2:\n",
    "        # If 3D, likely from multi-class, take the last dimension\n",
    "        shap_values = shap_values[:, :, -1] if shap_values.shape[2] > 1 else shap_values[:, :, 0]\n",
    "\n",
    "    # Use subset of data for visualization if too large\n",
    "    max_samples_for_viz = min(100, shap_values.shape[0])\n",
    "    shap_values_viz = shap_values[:max_samples_for_viz]\n",
    "    X_test_viz = X_test.iloc[:max_samples_for_viz]\n",
    "\n",
    "    print(f\"   📊 Using {max_samples_for_viz} samples for visualization\")\n",
    "    print(f\"   📊 Final SHAP values shape: {shap_values_viz.shape}\")\n",
    "\n",
    "    # SHAP Summary Plot with error handling\n",
    "    print(\"\\n2. Generating SHAP visualizations...\")\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_viz, X_test_viz, feature_names=X.columns, show=False, max_display=15)\n",
    "        plt.title('SHAP Feature Importance Summary', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"   ✅ SHAP summary plot generated successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Could not generate SHAP summary plot: {e}\")\n",
    "        print(\"   📊 Generating alternative feature importance plot...\")\n",
    "\n",
    "        # Alternative: Bar plot of mean absolute SHAP values\n",
    "        # Fix: Ensure we calculate mean correctly\n",
    "        mean_shap_importance = np.abs(shap_values_viz).mean(axis=0)  # Mean across samples (axis=0)\n",
    "\n",
    "        feature_importance_shap = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': mean_shap_importance\n",
    "        }).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.barh(range(len(feature_importance_shap)), feature_importance_shap['importance'][::-1])\n",
    "        plt.yticks(range(len(feature_importance_shap)), feature_importance_shap['feature'][::-1])\n",
    "        plt.xlabel('Mean |SHAP Value|')\n",
    "        plt.title('Feature Importance (SHAP Values)', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Calculate feature importance from SHAP values - FIXED VERSION\n",
    "    print(\"\\n   📊 Calculating feature importance from SHAP values...\")\n",
    "    try:\n",
    "        # Ensure we calculate the mean across the correct axis (samples)\n",
    "        if shap_values_viz.ndim == 2:\n",
    "            mean_importance = np.abs(shap_values_viz).mean(axis=0)  # Mean across samples\n",
    "        else:\n",
    "            mean_importance = np.abs(shap_values_viz)\n",
    "\n",
    "        # Ensure the arrays have the same length\n",
    "        if len(mean_importance) != len(X.columns):\n",
    "            print(f\"   ⚠️ Dimension mismatch: SHAP values {len(mean_importance)} vs features {len(X.columns)}\")\n",
    "            # Truncate or pad as needed\n",
    "            if len(mean_importance) > len(X.columns):\n",
    "                mean_importance = mean_importance[:len(X.columns)]\n",
    "            else:\n",
    "                # Pad with zeros if needed\n",
    "                mean_importance = np.pad(mean_importance, (0, len(X.columns) - len(mean_importance)), 'constant')\n",
    "\n",
    "        feature_importance_shap = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': mean_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(\"   ✅ Feature importance calculated successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error calculating feature importance: {e}\")\n",
    "        # Fallback: create dummy importance\n",
    "        feature_importance_shap = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': np.random.rand(len(X.columns))\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"\\n📊 Top 10 Most Important Features (SHAP):\")\n",
    "    print(feature_importance_shap.head(10))\n",
    "\n",
    "    # SHAP Waterfall plot for a specific prediction\n",
    "    print(\"\\n3. Generating SHAP explanation for sample prediction...\")\n",
    "    try:\n",
    "        sample_idx = 0  # First sample\n",
    "\n",
    "        # Create a simple explanation plot instead of waterfall\n",
    "        if shap_values_viz.ndim == 2 and sample_idx < shap_values_viz.shape[0]:\n",
    "            sample_shap = shap_values_viz[sample_idx]\n",
    "            sample_data = X_test_viz.iloc[sample_idx]\n",
    "\n",
    "            # Get top contributing features\n",
    "            feature_contributions = pd.DataFrame({\n",
    "                'feature': X.columns[:len(sample_shap)],  # Ensure same length\n",
    "                'shap_value': sample_shap,\n",
    "                'feature_value': sample_data.values[:len(sample_shap)]\n",
    "            }).sort_values('shap_value', key=abs, ascending=False).head(10)\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            colors = ['red' if x < 0 else 'green' for x in feature_contributions['shap_value']]\n",
    "            plt.barh(range(len(feature_contributions)), feature_contributions['shap_value'], color=colors)\n",
    "            plt.yticks(range(len(feature_contributions)), feature_contributions['feature'])\n",
    "            plt.xlabel('SHAP Value')\n",
    "            plt.title(f'SHAP Values for Sample Prediction\\n'\n",
    "                     f'Actual: {\"Churn\" if y_test.iloc[sample_idx] == 1 else \"No Churn\"}, '\n",
    "                     f'Predicted: {\"Churn\" if best_predictions[sample_idx] == 1 else \"No Churn\"}',\n",
    "                     fontweight='bold')\n",
    "            plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            print(\"   ✅ SHAP explanation plot generated successfully!\")\n",
    "        else:\n",
    "            print(\"   ⚠️ Unable to generate sample prediction plot due to data dimensions\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Could not generate SHAP waterfall plot: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"   ❌ SHAP analysis failed, continuing with model-based feature importance...\")\n",
    "\n",
    "    # Fallback to model's built-in feature importance\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance_shap = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    elif hasattr(best_model, 'coef_'):\n",
    "        feature_importance_shap = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': np.abs(best_model.coef_[0])\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    else:\n",
    "        # Create dummy importance for demonstration\n",
    "        feature_importance_shap = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': np.random.rand(len(X.columns))\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(f\"📊 Using {best_model_name} built-in feature importance\")\n",
    "\n",
    "# LIME Explainer\n",
    "print(\"\\n4. Setting up LIME explainer...\")\n",
    "try:\n",
    "    lime_explainer = LimeTabularExplainer(\n",
    "        X_train.values,\n",
    "        feature_names=X.columns.tolist(),\n",
    "        class_names=['No Churn', 'Churn'],\n",
    "        mode='classification',\n",
    "        discretize_continuous=True\n",
    "    )\n",
    "\n",
    "    # LIME explanation for a sample\n",
    "    sample_idx = 0\n",
    "    print(\"   🔍 Generating LIME explanation for sample prediction...\")\n",
    "\n",
    "    lime_explanation = lime_explainer.explain_instance(\n",
    "        X_test.iloc[sample_idx].values,\n",
    "        best_model.predict_proba,\n",
    "        num_features=10,\n",
    "        top_labels=1\n",
    "    )\n",
    "\n",
    "    # Display LIME explanation\n",
    "    print(f\"\\n📋 LIME Explanation for Sample {sample_idx}:\")\n",
    "    prediction_proba = best_model.predict_proba(X_test.iloc[sample_idx:sample_idx+1])[0]\n",
    "    print(f\"   Prediction probability: {prediction_proba[1]:.4f}\")\n",
    "    print(\"\\n   Top contributing features:\")\n",
    "\n",
    "    lime_features = lime_explanation.as_list()\n",
    "    for feature, contribution in lime_features:\n",
    "        print(f\"   {feature}: {contribution:.4f}\")\n",
    "\n",
    "    # Create LIME visualization\n",
    "    try:\n",
    "        fig = lime_explanation.as_pyplot_figure()\n",
    "        fig.suptitle(f'LIME Feature Explanation - Sample Prediction\\n'\n",
    "                    f'Actual: {\"Churn\" if y_test.iloc[sample_idx] == 1 else \"No Churn\"}, '\n",
    "                    f'Predicted: {\"Churn\" if best_predictions[sample_idx] == 1 else \"No Churn\"}',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"   ✅ LIME explanation plot generated successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Could not generate LIME plot: {e}\")\n",
    "\n",
    "        # Alternative LIME visualization\n",
    "        lime_df = pd.DataFrame(lime_features, columns=['Feature', 'Contribution'])\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        colors = ['red' if x < 0 else 'green' for x in lime_df['Contribution']]\n",
    "        plt.barh(range(len(lime_df)), lime_df['Contribution'], color=colors)\n",
    "        plt.yticks(range(len(lime_df)), lime_df['Feature'])\n",
    "        plt.xlabel('LIME Contribution')\n",
    "        plt.title('LIME Feature Contributions', fontweight='bold')\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ LIME explainer failed: {e}\")\n",
    "    print(\"   📊 Skipping LIME analysis...\")\n",
    "\n",
    "# Global feature importance comparison\n",
    "print(\"\\n5. Comparing feature importance across methods...\")\n",
    "\n",
    "# Get feature importance from the model itself\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    model_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'model_importance': best_model.feature_importances_\n",
    "    })\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    model_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'model_importance': np.abs(best_model.coef_[0])\n",
    "    })\n",
    "else:\n",
    "    # Fallback for models without built-in importance\n",
    "    model_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'model_importance': np.random.rand(len(X.columns))\n",
    "    })\n",
    "\n",
    "# Merge importance scores\n",
    "importance_comparison = model_importance.merge(\n",
    "    feature_importance_shap[['feature', 'importance']], on='feature', suffixes=('', '_shap')\n",
    ")\n",
    "\n",
    "# Normalize scores for comparison\n",
    "importance_comparison['model_importance_norm'] = (\n",
    "    importance_comparison['model_importance'] / importance_comparison['model_importance'].max()\n",
    ")\n",
    "importance_comparison['shap_importance_norm'] = (\n",
    "    importance_comparison['importance'] / importance_comparison['importance'].max()\n",
    ")\n",
    "\n",
    "# Sort by SHAP importance and take top 15\n",
    "top_features = importance_comparison.nlargest(15, 'importance')\n",
    "\n",
    "# Create comparison plot\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    x = np.arange(len(top_features))\n",
    "    width = 0.35\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, top_features['model_importance_norm'], width,\n",
    "                   label=f'{best_model_name} Importance', alpha=0.8, color='lightblue')\n",
    "    bars2 = ax.bar(x + width/2, top_features['shap_importance_norm'], width,\n",
    "                   label='SHAP Importance', alpha=0.8, color='lightcoral')\n",
    "\n",
    "    ax.set_xlabel('Features')\n",
    "    ax.set_ylabel('Normalized Importance Score')\n",
    "    ax.set_title('Feature Importance Comparison: Model vs SHAP', fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_features['feature'], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"   ✅ Feature importance comparison plot generated!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️ Could not generate comparison plot: {e}\")\n",
    "\n",
    "# Business insights from explainability\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎯 BUSINESS INSIGHTS FROM MODEL EXPLAINABILITY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "top_5_features = feature_importance_shap.head(5)\n",
    "print(\"Top 5 factors influencing customer churn:\")\n",
    "for i, (_, row) in enumerate(top_5_features.iterrows(), 1):\n",
    "    print(f\"{i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# Actionable insights\n",
    "print(f\"\\n💡 ACTIONABLE INSIGHTS:\")\n",
    "insights = []\n",
    "\n",
    "for feature in top_5_features['feature']:\n",
    "    if 'Contract' in feature and 'month' in feature.lower():\n",
    "        insights.append(\"📋 Contract type is crucial - focus on converting month-to-month customers to longer contracts\")\n",
    "    elif 'tenure' in feature.lower():\n",
    "        insights.append(\"⏱️  Customer tenure is key - implement early retention programs for new customers\")\n",
    "    elif 'charges' in feature.lower():\n",
    "        insights.append(\"💰 Pricing strategy matters - consider personalized pricing for at-risk customers\")\n",
    "    elif 'Internet' in feature or 'Service' in feature:\n",
    "        insights.append(\"🌐 Service offerings impact retention - bundle services strategically\")\n",
    "    elif 'Payment' in feature:\n",
    "        insights.append(\"💳 Payment method affects churn - encourage automatic payments\")\n",
    "    elif 'Online' in feature or 'Tech' in feature:\n",
    "        insights.append(\"🛡️ Additional services provide stickiness - promote security and support services\")\n",
    "\n",
    "# Remove duplicates and print insights\n",
    "unique_insights = list(set(insights))\n",
    "for insight in unique_insights:\n",
    "    print(f\"   {insight}\")\n",
    "\n",
    "print(f\"\\n✅ MODEL EXPLAINABILITY ANALYSIS COMPLETED!\")\n",
    "print(f\"🔍 Key drivers of churn identified and visualized!\")\n",
    "print(f\"📊 Ready to build the Streamlit dashboard!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4zHF0pG_NXR",
    "outputId": "4e8c0fa3-e571-4679-ab8c-5e177d05203a"
   },
   "outputs": [],
   "source": [
    "# 1. First install dependencies\n",
    "global df  # Allows access to the Kaggle-loaded dataframe\n",
    "!pip install streamlit pyngrok pandas numpy plotly scikit-learn xgboost\n",
    "\n",
    "!ngrok authtoken 2wbNxDgQWDUhxZi8dxOPEkLxl3Q_FErVaXD76Kqxj3bycu8r\n",
    "\n",
    "# 2. Write the Streamlit app to a file (alternative method)\n",
    "from google.colab import files\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyM2_LwrJmBh"
   },
   "outputs": [],
   "source": [
    "streamlit_code = \"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Customer Churn Prediction Dashboard\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Custom CSS for better styling\n",
    "st.markdown('''\n",
    "<style>\n",
    "    .main-header {\n",
    "        font-size: 3rem;\n",
    "        color: #1f77b4;\n",
    "        text-align: center;\n",
    "        margin-bottom: 2rem;\n",
    "    }\n",
    "    .metric-card {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 1rem;\n",
    "        border-radius: 10px;\n",
    "        border-left: 5px solid #1f77b4;\n",
    "    }\n",
    "    .churn-risk-high {\n",
    "        background-color: #ffebee;\n",
    "        border-left: 5px solid #f44336;\n",
    "    }\n",
    "    .churn-risk-medium {\n",
    "        background-color: #fff3e0;\n",
    "        border-left: 5px solid #ff9800;\n",
    "    }\n",
    "    .churn-risk-low {\n",
    "        background-color: #e8f5e8;\n",
    "        border-left: 5px solid #4caf50;\n",
    "    }\n",
    "</style>\n",
    "''', unsafe_allow_html=True)\n",
    "\n",
    "# Title\n",
    "st.markdown('<h1 class=\"main-header\">🎯 Customer Churn Prediction Dashboard</h1>', unsafe_allow_html=True)\n",
    "\n",
    "# [Previous cache decorators and functions...]\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    try:\n",
    "        data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            data = pd.read_csv('telco_churn.csv')\n",
    "        except FileNotFoundError:\n",
    "            st.warning(\"Using sample data as real dataset not found. Please upload 'WA_Fn-UseC_-Telco-Customer-Churn.csv' for full functionality.\")\n",
    "            np.random.seed(42)\n",
    "            n_samples = 1000\n",
    "\n",
    "            data = pd.DataFrame({\n",
    "                'customerID': [f'C{i:04d}' for i in range(n_samples)],\n",
    "                'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "                'SeniorCitizen': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),\n",
    "                'Partner': np.random.choice(['Yes', 'No'], n_samples),\n",
    "                'Dependents': np.random.choice(['Yes', 'No'], n_samples),\n",
    "                'tenure': np.random.randint(1, 73, n_samples),\n",
    "                'PhoneService': np.random.choice(['Yes', 'No'], n_samples, p=[0.9, 0.1]),\n",
    "                'MultipleLines': np.random.choice(['Yes', 'No', 'No phone service'], n_samples),\n",
    "                'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples),\n",
    "                'OnlineSecurity': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),\n",
    "                'OnlineBackup': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),\n",
    "                'DeviceProtection': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),\n",
    "                'TechSupport': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),\n",
    "                'StreamingTV': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),\n",
    "                'StreamingMovies': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),\n",
    "                'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples, p=[0.5, 0.3, 0.2]),\n",
    "                'PaperlessBilling': np.random.choice(['Yes', 'No'], n_samples),\n",
    "                'PaymentMethod': np.random.choice([\n",
    "                    'Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'\n",
    "                ], n_samples),\n",
    "                'MonthlyCharges': np.random.uniform(18, 120, n_samples),\n",
    "                'TotalCharges': np.random.uniform(18, 8000, n_samples),\n",
    "                'Churn': np.random.choice(['Yes', 'No'], n_samples, p=[0.27, 0.73])\n",
    "            })\n",
    "    return data\n",
    "\n",
    "@st.cache_data\n",
    "def preprocess_data(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    # Convert TotalCharges to numeric (handle empty strings)\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n",
    "\n",
    "    # Create binary target\n",
    "    df['Churn_Binary'] = (df['Churn'] == 'Yes').astype(int)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    categorical_columns = categorical_columns.drop(['customerID', 'Churn'], errors='ignore')\n",
    "\n",
    "    df_encoded = df.copy()\n",
    "    label_encoders = {}\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    return df_encoded, label_encoders\n",
    "\n",
    "@st.cache_resource\n",
    "def train_and_save_models(X, y):\n",
    "    MODEL_FILE = 'churn_models.pkl'\n",
    "\n",
    "    if os.path.exists(MODEL_FILE):\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    }\n",
    "\n",
    "    # Train and evaluate models\n",
    "    model_results = {}\n",
    "    trained_models = {}\n",
    "    scalers = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        if name == 'Logistic Regression':\n",
    "            # Scale features for Logistic Regression\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            scalers[name] = scaler\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            scalers[name] = None\n",
    "\n",
    "        trained_models[name] = model\n",
    "\n",
    "        model_results[name] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba,\n",
    "            'X_test': X_test if name != 'Logistic Regression' else X_test_scaled,\n",
    "            'y_test': y_test\n",
    "        }\n",
    "\n",
    "    # Find best model based on F1 score\n",
    "    best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['f1'])\n",
    "    best_model = trained_models[best_model_name]\n",
    "    best_scaler = scalers[best_model_name]\n",
    "\n",
    "    # Save models\n",
    "    with open(MODEL_FILE, 'wb') as f:\n",
    "        pickle.dump((\n",
    "            model_results,\n",
    "            trained_models,\n",
    "            best_model_name,\n",
    "            best_model,\n",
    "            best_scaler,\n",
    "            X_test,\n",
    "            y_test\n",
    "        ), f)\n",
    "\n",
    "    return model_results, trained_models, best_model_name, best_model, best_scaler, X_test, y_test\n",
    "\n",
    "# Load and prepare data\n",
    "data = load_data()\n",
    "df_processed, label_encoders = preprocess_data(data)\n",
    "\n",
    "# Prepare features for modeling\n",
    "feature_columns = df_processed.columns.drop(['customerID', 'Churn', 'Churn_Binary'], errors='ignore')\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['Churn_Binary']\n",
    "\n",
    "# Train or load models\n",
    "model_results, trained_models, best_model_name, best_model, best_scaler, X_test, y_test = train_and_save_models(X, y)\n",
    "\n",
    "# Sidebar\n",
    "page = st.sidebar.selectbox(\n",
    "    \"Main page:\",\n",
    "    [\"🏠 Overview\"]\n",
    ")\n",
    "\n",
    "# [Rest of your Streamlit page routing and visualizations...]\n",
    "if page == \"🏠 Overview\":\n",
    "    st.markdown(\"## 📋 Dataset Overview\")\n",
    "\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "\n",
    "    with col1:\n",
    "        st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Total Customers\", f\"{len(data):,}\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    with col2:\n",
    "        churn_rate = (data['Churn'] == 'Yes').mean() * 100\n",
    "        st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Churn Rate\", f\"{churn_rate:.1f}%\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    with col3:\n",
    "        avg_tenure = data['tenure'].mean()\n",
    "        st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Avg. Tenure\", f\"{avg_tenure:.1f} months\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    with col4:\n",
    "        avg_charges = data['MonthlyCharges'].mean()\n",
    "        st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
    "        st.metric(\"Avg. Monthly Charges\", f\"${avg_charges:.2f}\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "    st.markdown(\"## 📊 Key Visualizations\")\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        # Churn distribution\n",
    "        fig_churn = px.pie(data, names='Churn', title='Customer Churn Distribution',\n",
    "                          color_discrete_sequence=['#2E8B57', '#FF6B6B'])\n",
    "        fig_churn.update_traces(textposition='inside', textinfo='percent+label')\n",
    "        st.plotly_chart(fig_churn, use_container_width=True)\n",
    "\n",
    "    with col2:\n",
    "        # Monthly charges by churn\n",
    "        fig_charges = px.box(data, x='Churn', y='MonthlyCharges',\n",
    "                           title='Monthly Charges by Churn Status',\n",
    "                           color='Churn', color_discrete_sequence=['#2E8B57', '#FF6B6B'])\n",
    "        st.plotly_chart(fig_charges, use_container_width=True)\n",
    "\n",
    "    # Contract type vs Churn\n",
    "    contract_churn = pd.crosstab(data['Contract'], data['Churn'], normalize='index') * 100\n",
    "    fig_contract = px.bar(contract_churn, title='Churn Rate by Contract Type (%)',\n",
    "                         color_discrete_sequence=['#2E8B57', '#FF6B6B'])\n",
    "    fig_contract.update_layout(yaxis_title='Percentage', xaxis_title='Contract Type')\n",
    "    st.plotly_chart(fig_contract, use_container_width=True)\n",
    "\n",
    "# [Continue with all other pages and functionality...]\n",
    "\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown('''\n",
    "<div style='text-align: center; color: #666; padding: 20px;'>\n",
    "    <p>🎯 Customer Churn Prediction Dashboard | Built with Streamlit & Machine Learning</p>\n",
    "    <p>💡 Empowering data-driven retention strategies for business growth</p>\n",
    "</div>\n",
    "''', unsafe_allow_html=True)\n",
    "\n",
    "# Sidebar information\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.markdown(\"### 📊 Dashboard Info\")\n",
    "st.sidebar.info(f'''\n",
    "**Model Used:** {best_model_name}\n",
    "**Accuracy:** {model_results[best_model_name]['accuracy']:.1%}\n",
    "**Total Customers:** {len(data):,}\n",
    "**Churn Rate:** {(data['Churn'] == 'Yes').mean():.1%}\n",
    "''')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDMilKhIKg-N",
    "outputId": "271d69da-a2fa-46a2-b6be-d44427183286"
   },
   "outputs": [],
   "source": [
    "with open('app.py', 'w') as f:\n",
    "    f.write(streamlit_code)\n",
    "\n",
    "# Run with ngrok\n",
    "from pyngrok import ngrok\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "# Start Streamlit\n",
    "def run_streamlit():\n",
    "    subprocess.run(['streamlit', 'run', 'app.py', '--server.port', '8501', '--server.headless', 'true'])\n",
    "\n",
    "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "# Set up ngrok\n",
    "public_url = ngrok.connect(8501)\n",
    "print(\"Your dashboard is ready at:\", public_url.public_url)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
